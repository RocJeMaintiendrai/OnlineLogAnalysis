# Name the components on this agent
log-agent.sources = exec-source
log-agent.sinks = kafka-sink
log-agent.channels = memory-channel

# Describe/configure the custom exec source
log-agent.sources.exec-source.type = com.onlinelog.analysis.ExecSource_JSON


log-agent.sources.exec-source.command = tail -F /home/hadoop/data/test/hadoop-cmf-hdfs-NAMENODE-yws76.log.out
log-agent.sources.exec-source.hostname = yws76
log-agent.sources.exec-source.servicename = namenode


# Describe the sink
log-agent.sinks.kafka-sink.type = org.apache.flume.sink.kafka.KafkaSink
log-agent.sinks.kafka-sink.kafka.topic = online-log-analysis
log-agent.sinks.kafka-sink.kafka.bootstrap.servers = hadoop001:9092
log-agent.sinks.kafka-sink.kafka.flumeBatchSize = 6000
log-agent.sinks.kafka-sink.kafka.producer.acks = 1
log-agent.sinks.kafka-sink.kafka.producer.linger.ms = 1
log-agent.sinks.kafka-sink.kafka.producer.compression.type = snappy

# Use a channel which buffers events in memory
log-agent.channels.memory-channel.type = memory
log-agent.channels.memory-channel.keep-alive = 90
log-agent.channels.memory-channel.capacity = 2000000
log-agent.channels.memory-channel.transactionCapacity = 6000

# Bind the source and sink to the channel
log-agent.sources.exec-source.channels = memory-channel
log-agent.sinks.kafka-sink.channel = memory-channel
